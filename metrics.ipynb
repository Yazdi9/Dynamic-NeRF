{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lpips\n",
    "import os\n",
    "import imageio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Square Error\n",
    "class MSE(object):\n",
    "    def __call__(self, pred, gt):\n",
    "        return torch.mean((pred - gt) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak Signal to Noise Ratio\n",
    "class PSNR(object):\n",
    "    def __call__(self, pred, gt):\n",
    "        mse = torch.mean((pred - gt) ** 2)\n",
    "        return 10 * torch.log10(1 / mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structural similarity index\n",
    "class SSIM(object):\n",
    "    '''\n",
    "    borrowed from https://github.com/huster-wgm/Pytorch-metrics/blob/master/metrics.py\n",
    "    '''\n",
    "    def gaussian(self, w_size, sigma):\n",
    "        gauss = torch.Tensor([math.exp(-(x - w_size//2)**2/float(2*sigma**2)) for x in range(w_size)])\n",
    "        return gauss/gauss.sum()\n",
    "\n",
    "    def create_window(self, w_size, channel=1):\n",
    "        _1D_window = self.gaussian(w_size, 1.5).unsqueeze(1)\n",
    "        _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "        window = _2D_window.expand(channel, 1, w_size, w_size).contiguous()\n",
    "        return window\n",
    "\n",
    "    def __call__(self, y_pred, y_true, w_size=11, size_average=True, full=False):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            y_true : 4-d ndarray in [batch_size, channels, img_rows, img_cols]\n",
    "            y_pred : 4-d ndarray in [batch_size, channels, img_rows, img_cols]\n",
    "            w_size : int, default 11\n",
    "            size_average : boolean, default True\n",
    "            full : boolean, default False\n",
    "        return ssim, larger the better\n",
    "        \"\"\"\n",
    "        # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).\n",
    "        if torch.max(y_pred) > 128:\n",
    "            max_val = 255\n",
    "        else:\n",
    "            max_val = 1\n",
    "\n",
    "        if torch.min(y_pred) < -0.5:\n",
    "            min_val = -1\n",
    "        else:\n",
    "            min_val = 0\n",
    "        L = max_val - min_val\n",
    "\n",
    "        padd = 0\n",
    "        (_, channel, height, width) = y_pred.size()\n",
    "        window = self.create_window(w_size, channel=channel).to(y_pred.device)\n",
    "\n",
    "        mu1 = F.conv2d(y_pred, window, padding=padd, groups=channel)\n",
    "        mu2 = F.conv2d(y_true, window, padding=padd, groups=channel)\n",
    "\n",
    "        mu1_sq = mu1.pow(2)\n",
    "        mu2_sq = mu2.pow(2)\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "\n",
    "        sigma1_sq = F.conv2d(y_pred * y_pred, window, padding=padd, groups=channel) - mu1_sq\n",
    "        sigma2_sq = F.conv2d(y_true * y_true, window, padding=padd, groups=channel) - mu2_sq\n",
    "        sigma12 = F.conv2d(y_pred * y_true, window, padding=padd, groups=channel) - mu1_mu2\n",
    "\n",
    "        C1 = (0.01 * L) ** 2\n",
    "        C2 = (0.03 * L) ** 2\n",
    "\n",
    "        v1 = 2.0 * sigma12 + C2\n",
    "        v2 = sigma1_sq + sigma2_sq + C2\n",
    "        cs = torch.mean(v1 / v2)  # contrast sensitivity\n",
    "\n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
    "\n",
    "        if size_average:\n",
    "            ret = ssim_map.mean()\n",
    "        else:\n",
    "            ret = ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "        if full:\n",
    "            return ret, cs\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learned Perceptual Image Patch Similarity\n",
    "class LPIPS(object):\n",
    "    '''\n",
    "    borrowed from https://github.com/huster-wgm/Pytorch-metrics/blob/master/metrics.py\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.model = lpips.LPIPS(net='vgg').cuda()\n",
    "\n",
    "    def __call__(self, y_pred, y_true, normalized=True):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            y_true : 4-d ndarray in [batch_size, channels, img_rows, img_cols]\n",
    "            y_pred : 4-d ndarray in [batch_size, channels, img_rows, img_cols]\n",
    "            normalized : change [0,1] => [-1,1] (default by LPIPS)\n",
    "        return LPIPS, smaller the better\n",
    "        \"\"\"\n",
    "        if normalized:\n",
    "            y_pred = y_pred * 2.0 - 1.0\n",
    "            y_true = y_true * 2.0 - 1.0\n",
    "        error =  self.model.forward(y_pred, y_true)\n",
    "        return torch.mean(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_in_dir(imgs_dir):\n",
    "    imgs = []\n",
    "    fnames = os.listdir(imgs_dir)\n",
    "    fnames.sort()\n",
    "    for fname in fnames:\n",
    "        if fname == \"000.png\" :  # ignore canonical space, only evalute real scene\n",
    "            continue\n",
    "            \n",
    "        img_path = os.path.join(imgs_dir, fname)\n",
    "        img = imageio.imread(img_path)\n",
    "        img = (np.array(img) / 255.).astype(np.float32)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        imgs.append(img)\n",
    "    \n",
    "    imgs = np.stack(imgs)       \n",
    "    return imgs\n",
    "\n",
    "def estim_error(estim, gt):\n",
    "    errors = dict()\n",
    "    metric = MSE()\n",
    "    errors[\"mse\"] = metric(estim, gt).item()\n",
    "    metric = PSNR()\n",
    "    errors[\"psnr\"] = metric(estim, gt).item()\n",
    "    metric = SSIM()\n",
    "    errors[\"ssim\"] = metric(estim, gt).item()\n",
    "    metric = LPIPS()\n",
    "    errors[\"lpips\"] = metric(estim, gt).item()\n",
    "    return errors\n",
    "\n",
    "def save_error(errors, save_dir):\n",
    "    save_path = os.path.join(save_dir, \"metrics.txt\")\n",
    "    f = open(save_path,\"w\")\n",
    "    f.write( str(errors) )\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/apumarola/miniconda3/envs/nerf/lib/python3.6/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "{'mse': 0.0007424007053487003, 'psnr': 31.293617248535156, 'ssim': 0.9739180207252502, 'lpips': 0.026781609281897545}\n"
     ]
    }
   ],
   "source": [
    "files_dir = \"./logs/mutant/renderonly_test_799999/\"\n",
    "\n",
    "estim_dir = os.path.join(files_dir, \"estim\")\n",
    "gt_dir = os.path.join(files_dir, \"gt\")\n",
    "\n",
    "estim = read_images_in_dir(estim_dir)\n",
    "gt = read_images_in_dir(gt_dir)\n",
    "\n",
    "estim = torch.Tensor(estim).cuda()\n",
    "gt = torch.Tensor(gt).cuda()\n",
    "\n",
    "errors = estim_error(estim, gt)\n",
    "save_error(errors, files_dir)\n",
    "print(errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerf",
   "language": "python",
   "name": "nerf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}